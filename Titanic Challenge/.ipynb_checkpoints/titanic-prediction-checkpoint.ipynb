{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fef2f2e5",
   "metadata": {
    "papermill": {
     "duration": 0.007486,
     "end_time": "2023-12-04T02:26:49.171202",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.163716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Data Exploration\n",
    "\n",
    "- **Objective**: Understand the structure of the data, identify missing values, and gather basic statistics.\n",
    "- **Approach**:\n",
    "  - Load the training and test datasets.\n",
    "  - Display the first few rows to understand the features and data format.\n",
    "  - Check for missing values in both datasets.\n",
    "  - Gather basic descriptive statistics for numerical features.\n",
    "  - Inspect data types and non-null counts.\n",
    "- **Expected Outcome**: A clear understanding of the data's structure, existing missing values, and basic statistical properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77d3177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:26:49.188434Z",
     "iopub.status.busy": "2023-12-04T02:26:49.187513Z",
     "iopub.status.idle": "2023-12-04T02:26:49.334823Z",
     "shell.execute_reply": "2023-12-04T02:26:49.331708Z"
    },
    "papermill": {
     "duration": 0.159322,
     "end_time": "2023-12-04T02:26:49.337701",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.178379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Head:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "Test Data Head:\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
      "\n",
      "Missing Values in Training Data:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Test Data:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "\n",
      "Training Data Description:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Test Data Description:\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n",
      "\n",
      "Training Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Displaying the first few rows of the training dataset\n",
    "print(\"Training Data Head:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Displaying the first few rows of the test dataset\n",
    "print(\"\\nTest Data Head:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# Checking for missing values in the training dataset\n",
    "print(\"\\nMissing Values in Training Data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Checking for missing values in the test dataset\n",
    "print(\"\\nMissing Values in Test Data:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Basic statistics of the training dataset\n",
    "print(\"\\nTraining Data Description:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "# Basic statistics of the test dataset\n",
    "print(\"\\nTest Data Description:\")\n",
    "print(test_df.describe())\n",
    "\n",
    "# Displaying the data types and non-null counts\n",
    "print(\"\\nTraining Data Info:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nTest Data Info:\")\n",
    "print(test_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a528a0c",
   "metadata": {
    "papermill": {
     "duration": 0.007564,
     "end_time": "2023-12-04T02:26:49.352616",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.345052",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52f44d36",
   "metadata": {
    "papermill": {
     "duration": 0.007825,
     "end_time": "2023-12-04T02:26:49.367612",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.359787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Data Cleaning\n",
    "\n",
    "- **Objective**: Handle missing values, outliers, and potentially erroneous data.\n",
    "- **Approach**:\n",
    "  - Fill missing 'Age' values with the median age, as age is an important factor and median is less sensitive to outliers.\n",
    "  - Impute missing 'Embarked' values with the mode, considering it's a categorical variable.\n",
    "  - Fill missing 'Fare' values in the test dataset with the median fare.\n",
    "  - Drop the 'Cabin' column due to a high percentage of missing data, which might be less informative for the model.\n",
    "- **Expected Outcome**: A dataset with handled missing values, ready for feature engineering and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885796d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:26:49.385559Z",
     "iopub.status.busy": "2023-12-04T02:26:49.385026Z",
     "iopub.status.idle": "2023-12-04T02:26:49.413866Z",
     "shell.execute_reply": "2023-12-04T02:26:49.412059Z"
    },
    "papermill": {
     "duration": 0.041886,
     "end_time": "2023-12-04T02:26:49.416868",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.374982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values After Data Cleaning - Training Data:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values After Data Cleaning - Test Data:\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "# Filling missing values for 'Age' with the median age\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
    "\n",
    "# Filling missing values for 'Embarked' with the mode (most common value)\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Filling missing values for 'Fare' in the test dataset with the median fare\n",
    "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
    "\n",
    "# Dropping the 'Cabin' column due to a large number of missing values\n",
    "train_df.drop(columns=['Cabin'], inplace=True)\n",
    "test_df.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# Confirming the changes\n",
    "print(\"Missing Values After Data Cleaning - Training Data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values After Data Cleaning - Test Data:\")\n",
    "print(test_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de1953",
   "metadata": {
    "papermill": {
     "duration": 0.007876,
     "end_time": "2023-12-04T02:26:49.433330",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.425454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. Feature Engineering\n",
    "\n",
    "- **Objective**: Enhance the dataset with new features and convert categorical variables into a format suitable for modeling.\n",
    "- **Approach**:\n",
    "  - Create a new feature 'FamilySize' combining 'SibSp' and 'Parch'.\n",
    "  - Extract titles from the 'Name' column as a new feature to capture social status information.\n",
    "  - Perform one-hot encoding on categorical variables like 'Sex', 'Embarked', and extracted 'Title' to convert them into numerical format.\n",
    "  - Drop features that are less likely to contribute to the model's predictive power, such as 'Name', 'Ticket', and 'PassengerId'.\n",
    "- **Expected Outcome**: A dataset enriched with meaningful features, ready for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec39d041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:26:49.452698Z",
     "iopub.status.busy": "2023-12-04T02:26:49.452209Z",
     "iopub.status.idle": "2023-12-04T02:26:49.485711Z",
     "shell.execute_reply": "2023-12-04T02:26:49.484429Z"
    },
    "papermill": {
     "duration": 0.046407,
     "end_time": "2023-12-04T02:26:49.488893",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.442486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/nq2pw38x5yscjmdx_4zjzgn40000gn/T/ipykernel_3697/673078194.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df_aligned.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n",
      "/var/folders/d7/nq2pw38x5yscjmdx_4zjzgn40000gn/T/ipykernel_3697/673078194.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_aligned.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Creating new feature 'FamilySize' from 'SibSp' and 'Parch'\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
    "\n",
    "# Extracting title from 'Name' as a new feature\n",
    "train_df['Title'] = train_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test_df['Title'] = test_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# One-hot encoding for categorical variables 'Sex', 'Embarked', and 'Title'\n",
    "train_df_encoded = pd.get_dummies(train_df, columns=['Sex', 'Embarked', 'Title'])\n",
    "test_df_encoded = pd.get_dummies(test_df, columns=['Sex', 'Embarked', 'Title'])\n",
    "\n",
    "# Aligning the train and test dataframes to have the same set of columns\n",
    "common_cols = [col for col in train_df_encoded.columns if col in test_df_encoded.columns and col != 'Survived']\n",
    "train_df_aligned = train_df_encoded[common_cols + ['Survived']]\n",
    "test_df_aligned = test_df_encoded[common_cols]\n",
    "\n",
    "# Dropping columns that are unlikely to be useful for prediction\n",
    "train_df_aligned.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n",
    "test_df_aligned.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1a821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: /Users/kennethyap/Desktop/Data Science/Kaggle Challenges/Titanic Challenge/{sys.prefix}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270db462",
   "metadata": {
    "papermill": {
     "duration": 0.007823,
     "end_time": "2023-12-04T02:26:49.504287",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.496464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "- **Objective**: Explore the data to discover patterns, relationships, and insights.\n",
    "- **Approach**:\n",
    "  - Analyze survival rates across different categorical features like 'Pclass', 'Sex', and 'Embarked'.\n",
    "  - Investigate the distribution of 'Age' and its impact on survival.\n",
    "  - Examine the correlations between different features using a heatmap.\n",
    "- **Expected Outcome**: Insights that could influence feature selection, model choice, and understanding of factors affecting survival.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032791ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:26:49.522521Z",
     "iopub.status.busy": "2023-12-04T02:26:49.520825Z",
     "iopub.status.idle": "2023-12-04T02:26:54.571896Z",
     "shell.execute_reply": "2023-12-04T02:26:54.570370Z"
    },
    "papermill": {
     "duration": 5.066691,
     "end_time": "2023-12-04T02:26:54.578436",
     "exception": false,
     "start_time": "2023-12-04T02:26:49.511745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Importing visualization libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Setting the aesthetic style of the plots\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhitegrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Importing visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "# Analyzing survival rate by different features\n",
    "def plot_survival_rate(df, column, title):\n",
    "    survival_rate = df[[column, 'Survived']].groupby([column], as_index=False).mean()\n",
    "    sns.barplot(x=column, y='Survived', data=survival_rate)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plotting survival rate by Pclass\n",
    "plot_survival_rate(train_df_aligned, 'Pclass', 'Survival Rate by Passenger Class')\n",
    "\n",
    "# Check if 'Sex_female' and 'Embarked_C' are in columns\n",
    "if 'Sex_female' in train_df_aligned.columns and 'Embarked_C' in train_df_aligned.columns:\n",
    "    # Plotting survival rate by Sex\n",
    "    plot_survival_rate(train_df_aligned, 'Sex_female', 'Survival Rate by Gender')\n",
    "\n",
    "    # Plotting survival rate by Embarked location\n",
    "    plot_survival_rate(train_df_aligned, 'Embarked_C', 'Survival Rate by Embarkation Point')\n",
    "\n",
    "# Distribution of Age and its impact on Survival\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.kdeplot(train_df_aligned[train_df_aligned['Survived'] == 0]['Age'], shade=True, color=\"r\", label=\"Not Survived\")\n",
    "sns.kdeplot(train_df_aligned[train_df_aligned['Survived'] == 1]['Age'], shade=True, color=\"b\", label=\"Survived\")\n",
    "plt.title('Age Distribution - Survived vs Not Survived')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap of the dataset\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(train_df_aligned.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Titanic Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a76f61",
   "metadata": {
    "papermill": {
     "duration": 0.01505,
     "end_time": "2023-12-04T02:26:54.609022",
     "exception": false,
     "start_time": "2023-12-04T02:26:54.593972",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbb25267",
   "metadata": {
    "papermill": {
     "duration": 0.014517,
     "end_time": "2023-12-04T02:26:54.638426",
     "exception": false,
     "start_time": "2023-12-04T02:26:54.623909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5. Model Selection\n",
    "\n",
    "- **Objective**: Choose appropriate machine learning models for binary classification.\n",
    "- **Approach**:\n",
    "  - Include Support Vector Machines (SVM), K-Nearest Neighbors (KNN), RandomForest, GradientBoosting\n",
    "  - Initialize the models with default or basic parameters for initial testing.\n",
    "- **Expected Outcome**: A selection of models to be trained and evaluated on the Titanic dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef34106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:26:54.671383Z",
     "iopub.status.busy": "2023-12-04T02:26:54.670827Z",
     "iopub.status.idle": "2023-12-04T02:26:55.320717Z",
     "shell.execute_reply": "2023-12-04T02:26:55.319395Z"
    },
    "papermill": {
     "duration": 0.669915,
     "end_time": "2023-12-04T02:26:55.323553",
     "exception": false,
     "start_time": "2023-12-04T02:26:54.653638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary machine learning models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Defining a Support Vector Machine (SVM) model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Defining a K-Nearest Neighbors (KNN) model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Defining a Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Defining a Gradient Boosting model\n",
    "gradient_boosting_model = GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "# Creating a list of models\n",
    "models = [svm_model, knn_model, random_forest_model, gradient_boosting_model]\n",
    "\n",
    "# Printing out each model's name\n",
    "for model in models:\n",
    "    print(model.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc853b",
   "metadata": {
    "papermill": {
     "duration": 0.013987,
     "end_time": "2023-12-04T02:26:55.351879",
     "exception": false,
     "start_time": "2023-12-04T02:26:55.337892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6. Model Training and Hyperparameter Tuning\n",
    "\n",
    "- **Objective**: Train each selected model and tune their hyperparameters for optimal performance.\n",
    "- **Approach**:\n",
    "  - Split the dataset into training and validation sets.\n",
    "  - Use GridSearchCV for hyperparameter tuning on each model.\n",
    "  - Train SVM, KNN, Random Forest, and Gradient Boosting models.\n",
    "  - Evaluate each model's performance based on validation accuracy.\n",
    "- **Expected Outcome**: Optimally tuned models with their performance metrics, ready for final evaluation and selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87c5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:26:55.386149Z",
     "iopub.status.busy": "2023-12-04T02:26:55.385734Z",
     "iopub.status.idle": "2023-12-04T02:28:25.687002Z",
     "shell.execute_reply": "2023-12-04T02:28:25.685533Z"
    },
    "papermill": {
     "duration": 90.322287,
     "end_time": "2023-12-04T02:28:25.690122",
     "exception": false,
     "start_time": "2023-12-04T02:26:55.367835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Preparing the data\n",
    "X = train_df_aligned.drop('Survived', axis=1)\n",
    "y = train_df_aligned['Survived']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing models\n",
    "svm_model = SVC()\n",
    "knn_model = KNeighborsClassifier()\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100)\n",
    "gradient_boosting_model = GradientBoostingClassifier(n_estimators=100)\n",
    "models = [svm_model, knn_model, random_forest_model, gradient_boosting_model]\n",
    "\n",
    "# Function for training and tuning\n",
    "def train_and_evaluate_model(model, params, X_train, y_train, X_val, y_val):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    predictions = best_model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Validation Accuracy: {accuracy}\")\n",
    "    return best_model\n",
    "\n",
    "# Training and tuning each model\n",
    "trained_models = []\n",
    "for model in models:\n",
    "    params = {}\n",
    "    if model == svm_model:\n",
    "        params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "    elif model == knn_model:\n",
    "        params = {'n_neighbors': [3, 5, 7, 9]}\n",
    "    elif model == random_forest_model:\n",
    "        params = {'n_estimators': [50, 100, 150], 'max_depth': [3, 5, 7]}\n",
    "    elif model == gradient_boosting_model:\n",
    "        params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "\n",
    "    trained_model = train_and_evaluate_model(model, params, X_train, y_train, X_val, y_val)\n",
    "    trained_models.append(trained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578bc06",
   "metadata": {
    "papermill": {
     "duration": 0.014588,
     "end_time": "2023-12-04T02:28:25.719969",
     "exception": false,
     "start_time": "2023-12-04T02:28:25.705381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 7. Model Evaluation\n",
    "\n",
    "- **Objective**: Assess the performance of each trained model using validation data.\n",
    "- **Approach**:\n",
    "  - Utilize classification metrics such as accuracy, precision, recall, and F1-score for evaluation.\n",
    "  - Generate and examine confusion matrices for each model to understand their true positives, false positives, true negatives, and false negatives.\n",
    "- **Expected Outcome**: Detailed performance metrics for each model, providing insights into their strengths and weaknesses in predicting Titanic survivors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788ae02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:28:25.751958Z",
     "iopub.status.busy": "2023-12-04T02:28:25.751507Z",
     "iopub.status.idle": "2023-12-04T02:28:25.843427Z",
     "shell.execute_reply": "2023-12-04T02:28:25.841542Z"
    },
    "papermill": {
     "duration": 0.11248,
     "end_time": "2023-12-04T02:28:25.847294",
     "exception": false,
     "start_time": "2023-12-04T02:28:25.734814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing libraries for evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    predictions = model.predict(X_val)\n",
    "    print(f\"Evaluation for {model.__class__.__name__}:\")\n",
    "    print(classification_report(y_val, predictions))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, predictions))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Evaluating each trained model\n",
    "for model in trained_models:\n",
    "    evaluate_model(model, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f629f3f",
   "metadata": {
    "papermill": {
     "duration": 0.016376,
     "end_time": "2023-12-04T02:28:25.880416",
     "exception": false,
     "start_time": "2023-12-04T02:28:25.864040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8. Predictions on Test Data\n",
    "\n",
    "- **Objective**: Use the best-performing model to make predictions on the test dataset.\n",
    "- **Approach**:\n",
    "  - Select the best-performing model from the previous evaluation step.\n",
    "  - Use this model to predict the survival of passengers in the test dataset.\n",
    "  - Prepare a submission file in the format required by the competition (PassengerId, Survived).\n",
    "- **Expected Outcome**: A CSV file ready for submission to the Kaggle competition, containing predictions of survival for each passenger in the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe2c7f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:28:25.914594Z",
     "iopub.status.busy": "2023-12-04T02:28:25.913736Z",
     "iopub.status.idle": "2023-12-04T02:28:25.935377Z",
     "shell.execute_reply": "2023-12-04T02:28:25.934380Z"
    },
    "papermill": {
     "duration": 0.042352,
     "end_time": "2023-12-04T02:28:25.938378",
     "exception": false,
     "start_time": "2023-12-04T02:28:25.896026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'best_model' is the chosen model from the trained models\n",
    "best_model = trained_models[0]  \n",
    "\n",
    "# Making predictions on the test data\n",
    "test_predictions = best_model.predict(test_df_aligned)\n",
    "\n",
    "# Preparing the submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_df['PassengerId'],  # Assuming original test data has 'PassengerId'\n",
    "    \"Survived\": test_predictions\n",
    "})\n",
    "\n",
    "# Saving the submission file\n",
    "submission.to_csv('titanic_predictions.csv', index=False)\n",
    "\n",
    "# Displaying the first few rows of the submission file\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79620802",
   "metadata": {
    "papermill": {
     "duration": 0.015024,
     "end_time": "2023-12-04T02:28:25.968814",
     "exception": false,
     "start_time": "2023-12-04T02:28:25.953790",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 102.220256,
   "end_time": "2023-12-04T02:28:26.909878",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-04T02:26:44.689622",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
